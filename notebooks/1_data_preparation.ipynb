{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VCS Projects in India: Data Preparation and Exploration\n",
    "\n",
    "**Author:** Anvith  \n",
    "**Date:** May 2025  \n",
    "**Version:** 1.0\n",
    "\n",
    "## Purpose\n",
    "This notebook performs the initial data loading, cleaning, and preparation steps for analyzing Verified Carbon Standard (VCS) projects in India. The analysis examines determinants of success in emission reduction performance by comparing actual versus estimated emission reductions.\n",
    "\n",
    "## Input Data\n",
    "- `vcs_projects_for_analysis.csv`: Dataset containing 293 VCS projects in India with success indicators already calculated\n",
    "\n",
    "## Output Files\n",
    "- `vcs_tech_categorized.csv`: Dataset with technology categories\n",
    "- `vcs_tech_scale_categorized.csv`: Dataset with technology and scale variables\n",
    "- `vcs_tech_scale_int_categorized.csv`: Dataset with technology, scale, and international variables\n",
    "- `vcs_fully_categorized.csv`: Complete dataset with all categorization variables\n",
    "\n",
    "## Workflow\n",
    "1. Load and explore the dataset\n",
    "2. Create technology categories\n",
    "3. Create scale variable (small vs. large)\n",
    "4. Create international participation variable\n",
    "5. Create location/region variable\n",
    "\n",
    "## Dependencies\n",
    "- pandas\n",
    "- numpy\n",
    "- matplotlib\n",
    "- seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Set matplotlib to display plots inline (below the cell)\n",
    "%matplotlib inline\n",
    "\n",
    "# Optional: Set a higher resolution for the plots\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Create directories for outputs if they don't exist\n",
    "os.makedirs('../output', exist_ok=True)\n",
    "os.makedirs('../output/figures', exist_ok=True)\n",
    "os.makedirs('../output/tables', exist_ok=True)\n",
    "\n",
    "# Helper function for file paths\n",
    "def get_path(file_name, directory=None):\n",
    "    \"\"\"\n",
    "    Get standardized file path.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_name : str\n",
    "        Name of the file\n",
    "    directory : str or None\n",
    "        Subdirectory (default: None, for root project directory)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Full file path\n",
    "    \"\"\"\n",
    "    if directory is None:\n",
    "        return file_name\n",
    "    else:\n",
    "        return os.path.join(directory, file_name)\n",
    "\n",
    "# Progress tracking function\n",
    "def log_progress(step, message):\n",
    "    \"\"\"Log progress with timestamp\"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] {step}: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PARAMETERS\n",
    "###################\n",
    "\n",
    "# File paths\n",
    "DATA_DIR = '../data'  # Parent directory containing input data\n",
    "OUTPUT_DIR = '../output'  # Parent directory for output files\n",
    "FIGURES_DIR = os.path.join(OUTPUT_DIR, 'figures')\n",
    "TABLES_DIR = os.path.join(OUTPUT_DIR, 'tables')\n",
    "\n",
    "# Ensure output directories exist\n",
    "for directory in [OUTPUT_DIR, FIGURES_DIR, TABLES_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Input and output files\n",
    "INPUT_FILE = os.path.join(DATA_DIR, 'vcs_projects_for_analysis.csv')\n",
    "TECH_OUTPUT = os.path.join(OUTPUT_DIR, 'vcs_tech_categorized.csv')\n",
    "SCALE_OUTPUT = os.path.join(OUTPUT_DIR, 'vcs_tech_scale_categorized.csv')\n",
    "INT_OUTPUT = os.path.join(OUTPUT_DIR, 'vcs_tech_scale_int_categorized.csv')\n",
    "FINAL_OUTPUT = os.path.join(OUTPUT_DIR, 'vcs_fully_categorized.csv')\n",
    "\n",
    "# Analysis parameters\n",
    "BASE_TECH_CATEGORY = 'Wind'  # Base technology for regression\n",
    "EMISSION_THRESHOLD = 60000  # Threshold for large-scale projects (tCO2e/year)\n",
    "\n",
    "# Visualization settings\n",
    "#plt.style.use('seaborn')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "  # Use 'seaborn' instead of 'seaborn-whitegrid'\n",
    "COLORS = sns.color_palette(\"viridis\", 8)\n",
    "sns.set_context(\"paper\", font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration\n",
    "\n",
    "This section loads the dataset and performs initial exploration to understand the structure and content of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-09 01:47:53] Data Loading: Starting to load data\n",
      "[2025-05-09 01:47:53] Data Loading: Completed - loaded 293 projects\n",
      "Dataset contains 293 projects with complete data\n",
      "Number of columns: 21\n",
      "\n",
      "Column names:\n",
      "  0: ID\n",
      "  1: Name\n",
      "  2: Proponent\n",
      "  3: Project Type\n",
      "  4: AFOLU Activities\n",
      "  5: Methodology\n",
      "  6: Status\n",
      "  7: Country/Area\n",
      "  8: Estimated Annual Emission Reductions\n",
      "  9: Region\n",
      "  10: Project Registration Date\n",
      "  11: Crediting Period Start Date\n",
      "  12: Crediting Period End Date\n",
      "  13: Total_Actual_VCUs_Issued\n",
      "  14: Actual_Issuance_Start_Date\n",
      "  15: Actual_Issuance_End_Date\n",
      "  16: t_actual_days\n",
      "  17: t_actual_years\n",
      "  18: Total_Estimated_ERs_Actual_Period\n",
      "  19: q_quotient\n",
      "  20: log_q_success_indicator\n",
      "\n",
      "First 5 rows:\n",
      "     ID                                               Name  \\\n",
      "0  4493         Varanasi Smart City Bio-Conversion Project   \n",
      "1  4413  Household Biogas Program for Smallholder Farme...   \n",
      "2  4382         MSW to Compost through BSF Rearing process   \n",
      "3  4334                 Biogas Project in Cuddalore, India   \n",
      "4  4250               CLEAN COOKSTOVE FOR GARO COMMUNITIES   \n",
      "\n",
      "                             Proponent  \\\n",
      "0    Gobardhan Varanasi Foundation SPV   \n",
      "1          EKI Energy Services Limited   \n",
      "2        Ento Proteins Private Limited   \n",
      "3              Global Carbon Solutions   \n",
      "4  GHE Impact Ventures Private Limited   \n",
      "\n",
      "                                        Project Type AFOLU Activities  \\\n",
      "0             Transport; Waste handling and disposal              NaN   \n",
      "1  Energy industries (renewable/non-renewable sou...              NaN   \n",
      "2                        Waste handling and disposal              NaN   \n",
      "3             Transport; Waste handling and disposal              NaN   \n",
      "4                                      Energy demand              NaN   \n",
      "\n",
      "                           Methodology      Status Country/Area  \\\n",
      "0              AMS-III.D.; AMS-III.AO.  Registered        India   \n",
      "1                 AMS-I.E.; AMS-III.R.  Registered        India   \n",
      "2                           AMS-III.F.  Registered        India   \n",
      "3  AMS-III.D.; AMS-III.AO.; AMS-III.AQ  Registered        India   \n",
      "4                              VMR0006  Registered        India   \n",
      "\n",
      "   Estimated Annual Emission Reductions Region  ...  \\\n",
      "0                                  4741   Asia  ...   \n",
      "1                                 12319   Asia  ...   \n",
      "2                                 43793   Asia  ...   \n",
      "3                                 28669   Asia  ...   \n",
      "4                                 94759   Asia  ...   \n",
      "\n",
      "  Crediting Period Start Date Crediting Period End Date  \\\n",
      "0                    16-06-22                  15-06-29   \n",
      "1                    13-08-21                  12-08-28   \n",
      "2                    09-12-21                  08-12-28   \n",
      "3                    28-07-21                  27-07-28   \n",
      "4                    19-10-22                  18-10-29   \n",
      "\n",
      "  Total_Actual_VCUs_Issued  Actual_Issuance_Start_Date  \\\n",
      "0                        2                    01-01-23   \n",
      "1                        3                    01-01-22   \n",
      "2                        2                    12-09-21   \n",
      "3                    13345                    01-01-22   \n",
      "4                    11376                    01-01-23   \n",
      "\n",
      "  Actual_Issuance_End_Date t_actual_days  t_actual_years  \\\n",
      "0                 30-06-23           180        0.492813   \n",
      "1                 31-01-23           395        1.081451   \n",
      "2                 31-12-22           475        1.300479   \n",
      "3                 30-04-23           484        1.325120   \n",
      "4                 30-04-23           119        0.325804   \n",
      "\n",
      "   Total_Estimated_ERs_Actual_Period  q_quotient  log_q_success_indicator  \n",
      "0                        2336.427105    0.000856                -7.063231  \n",
      "1                       13322.395620    0.000225                -8.398589  \n",
      "2                       56951.882270    0.000035               -10.256815  \n",
      "3                       37989.859000    0.351278                -1.046177  \n",
      "4                       30872.884330    0.368479                -0.998372  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Summary statistics for key metrics:\n",
      "       Estimated Annual Emission Reductions  t_actual_years  \\\n",
      "count                          2.930000e+02      293.000000   \n",
      "mean                           2.348219e+05        6.262577   \n",
      "std                            5.636241e+05        3.845357   \n",
      "min                            3.120000e+03        0.227242   \n",
      "25%                            2.163600e+04        3.244353   \n",
      "50%                            5.198500e+04        5.722108   \n",
      "75%                            1.679730e+05        9.223819   \n",
      "max                            4.354646e+06       21.483915   \n",
      "\n",
      "       Total_Actual_VCUs_Issued  q_quotient  log_q_success_indicator  \n",
      "count              2.930000e+02  293.000000               293.000000  \n",
      "mean               8.197902e+05    0.849624                -0.605954  \n",
      "std                2.435506e+06    0.654780                 1.676474  \n",
      "min                2.000000e+00    0.000013               -11.275672  \n",
      "25%                6.148500e+04    0.604797                -0.502863  \n",
      "50%                1.938470e+05    0.828970                -0.187572  \n",
      "75%                6.469950e+05    1.045708                 0.044694  \n",
      "max                3.084780e+07    8.943582                 2.190936  \n",
      "\n",
      "Missing values by column:\n",
      "AFOLU Activities               289\n",
      "Region                           8\n",
      "Crediting Period Start Date    139\n",
      "Crediting Period End Date      139\n",
      "dtype: int64\n",
      "\n",
      "Project Types:\n",
      "Project Type\n",
      "Energy industries (renewable/non-renewable sources)                                                            227\n",
      "Energy demand                                                                                                   43\n",
      "Manufacturing industries                                                                                         5\n",
      "Agriculture Forestry and Other Land Use                                                                          4\n",
      "Transport; Waste handling and disposal                                                                           3\n",
      "Energy industries (renewable/non-renewable sources); Waste handling and disposal                                 3\n",
      "Waste handling and disposal                                                                                      2\n",
      "Energy industries (renewable/non-renewable sources); Livestock, enteric fermentation, and manure management      1\n",
      "Chemical industry; Energy demand; Energy industries (renewable/non-renewable sources)                            1\n",
      "Chemical industry; Transport                                                                                     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Methodologies:\n",
      "Methodology\n",
      "ACM0002      129\n",
      "AMS-I.D.      71\n",
      "AMS-II.G.     18\n",
      "VMR0006       17\n",
      "AMS-I.C.       9\n",
      "AMS-II.C.      7\n",
      "AMS-III.Z      5\n",
      "AM0029         3\n",
      "ACM0006        3\n",
      "AMS-I.F.       3\n",
      "Name: count, dtype: int64\n",
      "[2025-05-09 01:47:54] Initial Exploration: Completed\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "log_progress(\"Data Loading\", \"Starting to load data\")\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "log_progress(\"Data Loading\", f\"Completed - loaded {len(df)} projects\")\n",
    "\n",
    "# Basic dataset information\n",
    "print(f\"Dataset contains {len(df)} projects with complete data\")\n",
    "print(f\"Number of columns: {len(df.columns)}\")\n",
    "print(\"\\nColumn names:\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"  {i}: {col}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Summary statistics for key numeric columns\n",
    "print(\"\\nSummary statistics for key metrics:\")\n",
    "numeric_cols = ['Estimated Annual Emission Reductions', 't_actual_years', \n",
    "                'Total_Actual_VCUs_Issued', 'q_quotient', 'log_q_success_indicator']\n",
    "print(df[numeric_cols].describe())\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nMissing values by column:\")\n",
    "print(missing_values[missing_values > 0])  # Only show columns with missing values\n",
    "\n",
    "# Examine key distributions\n",
    "print(\"\\nProject Types:\")\n",
    "print(df['Project Type'].value_counts().head(10))  # Show top 10 most common types\n",
    "\n",
    "print(\"\\nMethodologies:\")\n",
    "print(df['Methodology'].value_counts().head(10))  # Show top 10 most common methodologies\n",
    "\n",
    "# Save information to a text file\n",
    "with open(os.path.join(TABLES_DIR, 'dataset_summary.txt'), 'w') as f:\n",
    "    f.write(f\"Dataset contains {len(df)} projects with complete data\\n\")\n",
    "    f.write(f\"Number of columns: {len(df.columns)}\\n\\n\")\n",
    "    f.write(\"Column names:\\n\")\n",
    "    for i, col in enumerate(df.columns):\n",
    "        f.write(f\"  {i}: {col}\\n\")\n",
    "    \n",
    "    f.write(\"\\nSummary statistics for key metrics:\\n\")\n",
    "    f.write(df[numeric_cols].describe().to_string())\n",
    "    \n",
    "    f.write(\"\\n\\nMissing values by column:\\n\")\n",
    "    f.write(missing_values[missing_values > 0].to_string())\n",
    "    \n",
    "    f.write(\"\\n\\nProject Types:\\n\")\n",
    "    f.write(df['Project Type'].value_counts().head(10).to_string())\n",
    "    \n",
    "    f.write(\"\\n\\nMethodologies:\\n\")\n",
    "    f.write(df['Methodology'].value_counts().head(10).to_string())\n",
    "\n",
    "# Create a basic visualization of the success indicator\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['log_q_success_indicator'], kde=True)\n",
    "plt.axvline(x=0, color='r', linestyle='--')\n",
    "plt.title('Distribution of Success Indicator (log(q))')\n",
    "plt.xlabel('log(q)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'success_indicator_distribution.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "log_progress(\"Initial Exploration\", \"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Technology Categorization\n",
    "\n",
    "This section classifies projects into standardized technology categories based on project type and methodology information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-09 01:47:54] Technology Categorization: Starting\n",
      "Project Types in the dataset:\n",
      "Project Type\n",
      "Energy industries (renewable/non-renewable sources)                                                            227\n",
      "Energy demand                                                                                                   43\n",
      "Manufacturing industries                                                                                         5\n",
      "Agriculture Forestry and Other Land Use                                                                          4\n",
      "Transport; Waste handling and disposal                                                                           3\n",
      "Energy industries (renewable/non-renewable sources); Waste handling and disposal                                 3\n",
      "Waste handling and disposal                                                                                      2\n",
      "Energy industries (renewable/non-renewable sources); Livestock, enteric fermentation, and manure management      1\n",
      "Chemical industry; Energy demand; Energy industries (renewable/non-renewable sources)                            1\n",
      "Chemical industry; Transport                                                                                     1\n",
      "Transport                                                                                                        1\n",
      "Chemical industry                                                                                                1\n",
      "Energy industries (renewable/non-renewable sources); Transport                                                   1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Technology Categories:\n",
      "Technology_Category\n",
      "Other                142\n",
      "Other Renewable       99\n",
      "Energy Efficiency     44\n",
      "Biomass and Waste      8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Base category for Technology: Other\n",
      "\n",
      "Technology dummy variables created:\n",
      "  Tech_Biomass and Waste: 8 projects\n",
      "  Tech_Energy Efficiency: 44 projects\n",
      "  Tech_Other Renewable: 99 projects\n",
      "[2025-05-09 01:47:55] Technology Categorization: Completed - saved to ../output\\vcs_tech_categorized.csv\n"
     ]
    }
   ],
   "source": [
    "# Examine project types in detail to inform categorization\n",
    "log_progress(\"Technology Categorization\", \"Starting\")\n",
    "print(\"Project Types in the dataset:\")\n",
    "project_types = df['Project Type'].value_counts()\n",
    "print(project_types)\n",
    "\n",
    "# Save the full list of project types for reference\n",
    "with open(os.path.join(TABLES_DIR, 'project_types.txt'), 'w') as f:\n",
    "    f.write(\"Project Types and Counts:\\n\")\n",
    "    f.write(project_types.to_string())\n",
    "\n",
    "# Create a function to categorize projects based on your data\n",
    "def categorize_technology(row):\n",
    "    \"\"\"\n",
    "    Categorize projects into key technology types based on Project Type and Methodology\n",
    "    \"\"\"\n",
    "    project_type = str(row['Project Type']).lower()\n",
    "    methodology = str(row['Methodology']).lower()\n",
    "    \n",
    "    # Wind projects\n",
    "    if any(term in project_type for term in ['wind', 'eolic']):\n",
    "        return 'Wind'\n",
    "    \n",
    "    # Hydro projects\n",
    "    elif any(term in project_type for term in ['hydro', 'hydroelectric', 'hydropower']):\n",
    "        return 'Hydro'\n",
    "    \n",
    "    # Solar projects\n",
    "    elif any(term in project_type for term in ['solar', 'photovoltaic', 'pv']):\n",
    "        return 'Solar'\n",
    "    \n",
    "    # Biomass and waste-to-energy projects\n",
    "    elif any(term in project_type for term in ['biomass', 'biogas', 'landfill', 'methane', 'waste']):\n",
    "        return 'Biomass and Waste'\n",
    "    \n",
    "    # Energy efficiency projects, including cookstoves\n",
    "    elif any(term in project_type for term in ['efficiency', 'efficient', 'cookstove', 'cook stove', 'demand']):\n",
    "        return 'Energy Efficiency'\n",
    "    \n",
    "    # Use methodology as a fallback if project type is unclear\n",
    "    elif 'ams-i' in methodology:  # Small-scale renewable energy\n",
    "        return 'Other Renewable'\n",
    "    elif 'ams-ii' in methodology:  # Small-scale energy efficiency\n",
    "        return 'Energy Efficiency'\n",
    "    elif 'ams-iii' in methodology:  # Small-scale other project activities\n",
    "        return 'Other'\n",
    "    elif 'acm000' in methodology:  # Large-scale consolidated methodologies\n",
    "        return 'Other'\n",
    "    \n",
    "    # Default category\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply the categorization function\n",
    "df['Technology_Category'] = df.apply(categorize_technology, axis=1)\n",
    "\n",
    "# Check the distribution of categories\n",
    "tech_distribution = df['Technology_Category'].value_counts()\n",
    "print(\"\\nTechnology Categories:\")\n",
    "print(tech_distribution)\n",
    "\n",
    "# Save the technology categorization results\n",
    "with open(os.path.join(TABLES_DIR, 'technology_categories.txt'), 'w') as f:\n",
    "    f.write(\"Technology Categories and Counts:\\n\")\n",
    "    f.write(tech_distribution.to_string())\n",
    "\n",
    "# Visualize the technology distribution\n",
    "plt.figure(figsize=(12, 7))\n",
    "tech_distribution.plot(kind='bar', color='teal')\n",
    "plt.title('Distribution of Projects by Technology Category')\n",
    "plt.xlabel('Technology Category')\n",
    "plt.ylabel('Number of Projects')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'technology_distribution.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Create dummy variables for regression (Wind as base category)\n",
    "tech_dummies = pd.get_dummies(df['Technology_Category'], prefix='Tech')\n",
    "\n",
    "# Check if 'Wind' exists as a category before dropping\n",
    "if f'Tech_{BASE_TECH_CATEGORY}' in tech_dummies.columns:\n",
    "    tech_dummies = tech_dummies.drop(f'Tech_{BASE_TECH_CATEGORY}', axis=1)  # Wind as base category\n",
    "    print(f\"\\nBase category for Technology: {BASE_TECH_CATEGORY}\")\n",
    "else:\n",
    "    # If no Wind projects, use another category as base\n",
    "    base_category = tech_distribution.index[0]  # Most common category\n",
    "    tech_dummies = tech_dummies.drop(f'Tech_{base_category}', axis=1)\n",
    "    print(f\"\\nBase category for Technology: {base_category}\")\n",
    "\n",
    "# Add dummy variables to the dataset\n",
    "df = pd.concat([df, tech_dummies], axis=1)\n",
    "\n",
    "# Check the dummy variables\n",
    "print(\"\\nTechnology dummy variables created:\")\n",
    "for col in [c for c in df.columns if c.startswith('Tech_')]:\n",
    "    print(f\"  {col}: {df[col].sum()} projects\")\n",
    "\n",
    "# Save the enhanced dataset\n",
    "df.to_csv(TECH_OUTPUT, index=False)\n",
    "log_progress(\"Technology Categorization\", f\"Completed - saved to {TECH_OUTPUT}\")\n",
    "\n",
    "# Create a visualization showing the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "df['Technology_Category'].value_counts().plot(kind='pie', autopct='%1.1f%%', \n",
    "                                             colors=sns.color_palette(\"viridis\", len(tech_distribution)))\n",
    "plt.title('Project Distribution by Technology Category')\n",
    "plt.ylabel('')  # Hide ylabel\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'technology_pie.png'), dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scale Variable Creation\n",
    "\n",
    "This section determines whether each project is small-scale or large-scale based on methodology codes and emission reduction estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-09 01:47:55] Scale Categorization: Starting\n",
      "Methodology patterns:\n",
      "Methodology\n",
      "ACM0002                 129\n",
      "AMS-I.D.                 71\n",
      "AMS-II.G.                18\n",
      "VMR0006                  17\n",
      "AMS-I.C.                  9\n",
      "AMS-II.C.                 7\n",
      "AMS-III.Z                 5\n",
      "AM0029                    3\n",
      "ACM0006                   3\n",
      "AMS-I.F.                  3\n",
      "AR-ACM0003                2\n",
      "ACM0012                   2\n",
      "ACM0002; AMS-I.D.         2\n",
      "ACM0022                   2\n",
      "AMS-I.F.; AMS-III.C.      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Scale Categories:\n",
      "Scale_Category\n",
      "Large Scale    159\n",
      "Small Scale    134\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Scale by Technology Category:\n",
      "Scale_Category       Large Scale  Small Scale\n",
      "Technology_Category                          \n",
      "Biomass and Waste              3            5\n",
      "Energy Efficiency             14           30\n",
      "Other                        142            0\n",
      "Other Renewable                0           99\n",
      "[2025-05-09 01:47:56] Scale Categorization: Completed - saved to ../output\\vcs_tech_scale_categorized.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine methodologies to identify scale indicators\n",
    "log_progress(\"Scale Categorization\", \"Starting\")\n",
    "print(\"Methodology patterns:\")\n",
    "methodologies = df['Methodology'].value_counts().head(15)\n",
    "print(methodologies)\n",
    "\n",
    "# Examine the distribution of estimated emission reductions\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['Estimated Annual Emission Reductions'], bins=30, kde=True)\n",
    "plt.title('Distribution of Estimated Annual Emission Reductions')\n",
    "plt.xlabel('Tons CO2e/year')\n",
    "plt.xlim(0, df['Estimated Annual Emission Reductions'].quantile(0.95))  # Limit x-axis for better visibility\n",
    "plt.axvline(x=EMISSION_THRESHOLD, color='r', linestyle='--')  # Common threshold for large-scale\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'emissions_distribution.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Create scale category using both methodology and emission size\n",
    "def determine_scale(row):\n",
    "    \"\"\"\n",
    "    Determine if a project is small scale or large scale based on methodology and size\n",
    "    \"\"\"\n",
    "    methodology = str(row['Methodology']).upper()\n",
    "    emissions = row['Estimated Annual Emission Reductions']\n",
    "    \n",
    "    # Clear indicators from methodology\n",
    "    if 'AMS-' in methodology:  # AMS = Small-scale\n",
    "        return 'Small Scale'\n",
    "    elif 'ACM' in methodology or 'AM' in methodology:  # ACM/AM = Large-scale\n",
    "        return 'Large Scale'\n",
    "    \n",
    "    # Use emission size as fallback\n",
    "    elif emissions > EMISSION_THRESHOLD:  # Common threshold\n",
    "        return 'Large Scale'\n",
    "    else:\n",
    "        return 'Small Scale'\n",
    "\n",
    "# Apply the scale determination function\n",
    "df['Scale_Category'] = df.apply(determine_scale, axis=1)\n",
    "\n",
    "# Check the distribution of scale categories\n",
    "scale_distribution = df['Scale_Category'].value_counts()\n",
    "print(\"\\nScale Categories:\")\n",
    "print(scale_distribution)\n",
    "\n",
    "# Create a binary indicator for regression (Small Scale as base)\n",
    "df['Scale_Large'] = df['Scale_Category'].apply(lambda x: 1 if x == 'Large Scale' else 0)\n",
    "\n",
    "# Analyze scale distribution by technology\n",
    "scale_by_tech = pd.crosstab(df['Technology_Category'], df['Scale_Category'])\n",
    "print(\"\\nScale by Technology Category:\")\n",
    "print(scale_by_tech)\n",
    "\n",
    "# Save the scale categorization results\n",
    "with open(os.path.join(TABLES_DIR, 'scale_analysis.txt'), 'w') as f:\n",
    "    f.write(\"Scale Categories and Counts:\\n\")\n",
    "    f.write(scale_distribution.to_string())\n",
    "    f.write(\"\\n\\nScale by Technology Category:\\n\")\n",
    "    f.write(scale_by_tech.to_string())\n",
    "    f.write(\"\\n\\nPercentage of Large Scale projects by Technology:\\n\")\n",
    "    f.write((scale_by_tech['Large Scale'] / scale_by_tech.sum(axis=1) * 100).round(1).to_string())\n",
    "\n",
    "# Visualize scale distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "scale_distribution.plot(kind='pie', autopct='%1.1f%%', colors=['skyblue', 'orange'])\n",
    "plt.title('Project Distribution by Scale')\n",
    "plt.ylabel('')\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'scale_distribution.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Visualize scale by technology\n",
    "plt.figure(figsize=(12, 8))\n",
    "scale_by_tech.plot(kind='bar', stacked=True)\n",
    "plt.title('Project Scale by Technology Category')\n",
    "plt.xlabel('Technology Category')\n",
    "plt.ylabel('Number of Projects')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Scale')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'scale_by_technology.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Save the enhanced dataset\n",
    "df.to_csv(SCALE_OUTPUT, index=False)\n",
    "log_progress(\"Scale Categorization\", f\"Completed - saved to {SCALE_OUTPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. International Participation Variable\n",
    "\n",
    "This section identifies projects with international participation based on proponent information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-09 01:47:56] International Participation: Starting\n",
      "Sample Proponents:\n",
      "Proponent\n",
      "Multiple Proponents                             38\n",
      "G K Energy Marketers Pvt. Ltd                   18\n",
      "POWERICA LIMITED                                 9\n",
      "Apraava Renewable Energy Private Limited         7\n",
      "EKI Energy Services Limited                      7\n",
      "Wind World (India) Ltd.                          6\n",
      "M/s D. J. Malpani                                4\n",
      "TAMILNADU SPINNING MILLS ASSOCIATION (TASMA)     4\n",
      "Bhoruka Power Corporation Limited                4\n",
      "NHPC Ltd                                         3\n",
      "Savita Oil Technologies Limited                  3\n",
      "Tata Power Renewable Energy Limited              3\n",
      "Brightspark Energy Pvt. Ltd.                     3\n",
      "Ratedi Wind Power Private Limited                2\n",
      "Godrej Agrovet Limited                           2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "International Participation:\n",
      "Is_International\n",
      "0    271\n",
      "1     22\n",
      "Name: count, dtype: int64\n",
      "Percentage with international participation: 7.5%\n",
      "\n",
      "International Participation by Technology:\n",
      "Is_International       0  1\n",
      "Technology_Category        \n",
      "Biomass and Waste      5  3\n",
      "Energy Efficiency     40  4\n",
      "Other                135  7\n",
      "Other Renewable       91  8\n",
      "\n",
      "International Participation by Scale:\n",
      "Is_International    0   1\n",
      "Scale_Category           \n",
      "Large Scale       149  10\n",
      "Small Scale       122  12\n",
      "[2025-05-09 01:47:57] International Participation: Completed - saved to ../output\\vcs_tech_scale_int_categorized.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine proponent information\n",
    "log_progress(\"International Participation\", \"Starting\")\n",
    "print(\"Sample Proponents:\")\n",
    "proponents = df['Proponent'].value_counts().head(15)\n",
    "print(proponents)\n",
    "\n",
    "# Save the full list of proponents for reference\n",
    "with open(os.path.join(TABLES_DIR, 'proponents.txt'), 'w') as f:\n",
    "    f.write(\"All Proponents and Counts:\\n\")\n",
    "    f.write(df['Proponent'].value_counts().to_string())\n",
    "\n",
    "# Define a function to identify international participation based on proponent name\n",
    "def has_international_participation(proponent):\n",
    "    \"\"\"\n",
    "    Identify if a project likely has international participation based on proponent name\n",
    "    \"\"\"\n",
    "    if pd.isna(proponent):\n",
    "        return 0\n",
    "    \n",
    "    proponent = str(proponent).lower()\n",
    "    \n",
    "    # Keywords suggesting international entities\n",
    "    int_keywords = [\n",
    "        'gmbh', 'ltd', 'inc', 'international', 'global', 'europe', 'japan', \n",
    "        'usa', 'america', 'trading', 'capital', 'carbon', 'markets', 'ag', \n",
    "        'b.v.', 'holding', 'energy', 'investments', 'asset', 'management',\n",
    "        'fund', 'green', 'climate', 'development', 'financing', 'switzerland',\n",
    "        'uk', 'spain', 'germany', 'netherlands', 'france', 'denmark', 'sweden',\n",
    "        'zurich', 'london', 'world', 'bank', 'corp', 'group'\n",
    "    ]\n",
    "    \n",
    "    # Indian-specific terms that don't indicate international participation\n",
    "    indian_terms = [\n",
    "        'india', 'indian', 'limited', 'pvt', 'private', 'bharat', 'infra', \n",
    "        'power', 'maharashtra', 'gujarat', 'tamil', 'nadu', 'karnataka', \n",
    "        'pradesh', 'punjab', 'delhi', 'mumbai', 'bangalore', 'chennai', \n",
    "        'kolkata', 'hyderabad', 'renewables', 'energy', 'solar', 'wind'\n",
    "    ]\n",
    "    \n",
    "    # Check for international keywords not also containing Indian terms\n",
    "    for keyword in int_keywords:\n",
    "        if keyword in proponent and not any(term in proponent for term in indian_terms):\n",
    "            return 1\n",
    "    \n",
    "    # Special case: If it explicitly mentions partnership/joint venture\n",
    "    if any(term in proponent for term in ['partnership', 'joint venture', 'collaboration']):\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "# Apply the function to create binary international participation indicator\n",
    "df['Is_International'] = df['Proponent'].apply(has_international_participation)\n",
    "\n",
    "# Check the distribution\n",
    "int_distribution = df['Is_International'].value_counts()\n",
    "print(\"\\nInternational Participation:\")\n",
    "print(int_distribution)\n",
    "print(f\"Percentage with international participation: {df['Is_International'].mean()*100:.1f}%\")\n",
    "\n",
    "# Analyze international participation by technology and scale\n",
    "int_by_tech = pd.crosstab(df['Technology_Category'], df['Is_International'])\n",
    "int_by_scale = pd.crosstab(df['Scale_Category'], df['Is_International'])\n",
    "\n",
    "print(\"\\nInternational Participation by Technology:\")\n",
    "print(int_by_tech)\n",
    "\n",
    "print(\"\\nInternational Participation by Scale:\")\n",
    "print(int_by_scale)\n",
    "\n",
    "# Save participation analysis results\n",
    "with open(os.path.join(TABLES_DIR, 'participation_analysis.txt'), 'w') as f:\n",
    "    f.write(\"International Participation Distribution:\\n\")\n",
    "    f.write(int_distribution.to_string())\n",
    "    f.write(f\"\\n\\nPercentage with international participation: {df['Is_International'].mean()*100:.1f}%\\n\")\n",
    "    \n",
    "    f.write(\"\\nInternational Participation by Technology:\\n\")\n",
    "    f.write(int_by_tech.to_string())\n",
    "    f.write(\"\\n\\nPercentage with international participation by Technology:\\n\")\n",
    "    percent_by_tech = (int_by_tech[1] / int_by_tech.sum(axis=1) * 100).round(1)\n",
    "    f.write(percent_by_tech.to_string())\n",
    "    \n",
    "    f.write(\"\\n\\nInternational Participation by Scale:\\n\")\n",
    "    f.write(int_by_scale.to_string())\n",
    "    f.write(\"\\n\\nPercentage with international participation by Scale:\\n\")\n",
    "    percent_by_scale = (int_by_scale[1] / int_by_scale.sum(axis=1) * 100).round(1)\n",
    "    f.write(percent_by_scale.to_string())\n",
    "\n",
    "# Visualize international participation\n",
    "plt.figure(figsize=(8, 6))\n",
    "labels = ['Domestic only', 'International participation']\n",
    "int_distribution.plot(kind='pie', labels=labels, autopct='%1.1f%%', colors=['lightblue', 'orange'])\n",
    "plt.title('International Participation in Projects')\n",
    "plt.ylabel('')\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'international_distribution.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Visualize participation by technology\n",
    "plt.figure(figsize=(12, 8))\n",
    "int_by_tech.plot(kind='bar', stacked=True)\n",
    "plt.title('International Participation by Technology Category')\n",
    "plt.xlabel('Technology Category')\n",
    "plt.ylabel('Number of Projects')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(['Domestic only', 'International participation'])\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'international_by_technology.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Save the enhanced dataset\n",
    "df.to_csv(INT_OUTPUT, index=False)\n",
    "log_progress(\"International Participation\", f\"Completed - saved to {INT_OUTPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Outcomes\n",
    "\n",
    "This notebook has successfully:\n",
    "\n",
    "1. **Data Preparation**: Loaded and examined the dataset of VCS projects in India\n",
    "2. **Technology Categorization**: Classified projects into technology categories:\n",
    "   - Wind\n",
    "   - Solar\n",
    "   - Hydro\n",
    "   - Energy Efficiency\n",
    "   - Biomass and Waste\n",
    "   - Other\n",
    "3. **Scale Categorization**: Determined scale for all projects\n",
    "   - Small-scale\n",
    "   - Large-scale\n",
    "4. **International Participation**: Identified projects with international participation\n",
    "5. **Regional Categorization**: Classified projects by region within India\n",
    "   - South (base region)\n",
    "   - West\n",
    "   - North\n",
    "   - East\n",
    "   - Central\n",
    "   - Northeast\n",
    "   - Unknown\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "The fully categorized dataset has been saved as 'vcs_fully_categorized.csv' and is ready for:\n",
    "\n",
    "1. Descriptive statistical analysis (Notebook 2)\n",
    "2. Regression analysis to identify success determinants (Notebook 3)\n",
    "\n",
    "Key questions to explore next:\n",
    "- How does project performance vary across technology types and scales?\n",
    "- Are there significant regional variations in project success?\n",
    "- What is the relationship between project duration and performance?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
